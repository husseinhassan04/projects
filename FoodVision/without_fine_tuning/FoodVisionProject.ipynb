{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f64911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b37eb5",
   "metadata": {},
   "source": [
    "# Download the Dataset (15 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5edae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load class names from metadata\n",
    "_, info = tfds.load('food101', split='train', with_info=True)\n",
    "all_classes = info.features['label'].names\n",
    "\n",
    "# Define the 15 selected classes\n",
    "selected_classes = [\n",
    "    'pizza', 'samosa', 'falafel', 'donuts', 'macaroni_and_cheese',\n",
    "    'caprese_salad', 'bibimbap', 'ceviche', 'bruschetta', 'beef_carpaccio',\n",
    "    'gnocchi', 'club_sandwich', 'grilled_cheese_sandwich', 'pad_thai', 'takoyaki'\n",
    "]\n",
    "selected_indices = tf.constant([all_classes.index(cls) for cls in selected_classes])\n",
    "\n",
    "# Filter and remap function\n",
    "def filter_classes(image, label):\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    return tf.reduce_any(tf.equal(label, selected_indices))\n",
    "\n",
    "def remap_labels(image, label):\n",
    "    label = tf.cast(label, tf.int32)\n",
    "    new_label = tf.argmax(tf.cast(tf.equal(label, selected_indices), tf.int32))\n",
    "    return image, new_label\n",
    "\n",
    "# Load and filter datasets\n",
    "training_set = tfds.load('food101', split='train[:90%]', as_supervised=True)\n",
    "validation_set = tfds.load('food101', split='train[90%:]', as_supervised=True)\n",
    "testing_set = tfds.load('food101', split='validation', as_supervised=True)\n",
    "\n",
    "training_set = training_set.filter(filter_classes).map(remap_labels)\n",
    "validation_set = validation_set.filter(filter_classes).map(remap_labels)\n",
    "testing_set = testing_set.filter(filter_classes).map(remap_labels)\n",
    "\n",
    "# Final class names for reference\n",
    "class_names = selected_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8ae07",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ff848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [224, 224]) / 255.0\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, 0.7, 1.3)\n",
    "    image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "    image = tf.image.random_hue(image, 0.05)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 230, 230)\n",
    "    image = tf.image.random_crop(image, [224, 224, 3])\n",
    "    return image, label\n",
    "\n",
    "training_set = (training_set\n",
    "                .map(preprocess_image)\n",
    "                .map(augment)\n",
    "                .shuffle(1000)\n",
    "                .batch(32)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "validation_set = (validation_set\n",
    "                  .map(preprocess_image)\n",
    "                  .batch(32)\n",
    "                  .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "testing_set = (testing_set\n",
    "               .map(preprocess_image)\n",
    "               .batch(32)\n",
    "               .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, info = tfds.load('food101', split='train', with_info=True)\n",
    "# class_names = info.features['label'].names[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(training_set))\n",
    "images, labels = batch\n",
    "\n",
    "images = images.numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    plt.imshow(np.clip(images[i], 0, 1))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fae879",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbad8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "\n",
    "    layers.Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(1024, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(512, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    # Final output layer for 15 classes\n",
    "    layers.Dense(15, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc6813",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(training_set,\n",
    "                    epochs=100,\n",
    "                    validation_data=validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679929d",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(testing_set)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a006d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, testing_set, class_names):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for images, labels in testing_set:\n",
    "        preds = model.predict(images)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(tf.argmax(preds, axis=1).numpy())\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be56ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, testing_set, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for images, labels in testing_set:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute and visualize the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3649ff1",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7a5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('food_vision_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02a3920",
   "metadata": {},
   "source": [
    "# Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c56922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img_path, model):\n",
    "    # Load and preprocess the image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img = img / 255.0\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(img)\n",
    "    predicted_index = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_class = class_names[predicted_index]\n",
    "    confidence = predictions[0][predicted_index]\n",
    "\n",
    "    # Output\n",
    "    print(f\"Prediction: {predicted_class} ({confidence:.2%} confidence)\")\n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39517170",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image(\"/content/baklava.jpg\", model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
